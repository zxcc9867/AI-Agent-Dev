from gpt_functions import (
    get_current_time,
    tools,
    get_yf_stock_info,
    get_yf_stock_history,
    get_yf_stock_recommendations,
)
from openai import OpenAI
from dotenv import load_dotenv
import os
import json
import streamlit as st
from collections import defaultdict

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")  # í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°

client = OpenAI(api_key=api_key)  # ì˜¤í”ˆAI í´ë¼ì´ì–¸íŠ¸ì˜ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±


def get_ai_response(messages, tools=None, stream=True):
    response = client.chat.completions.create(
        model="gpt-4o",  # ì‘ë‹µ ìƒì„±ì— ì‚¬ìš©í•  ëª¨ë¸ì„ ì§€ì •í•©ë‹ˆë‹¤.
        stream=stream,  # (1) ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ì„ ìœ„í•´ ì„¤ì •
        messages=messages,  # ëŒ€í™” ê¸°ë¡ì„ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.
        tools=tools,  # ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ì„ ì „ë‹¬í•©ë‹ˆë‹¤.
    )

    if stream:
        for chunk in response:
            yield chunk  # ìƒì„±ëœ ì‘ë‹µì˜ ë‚´ìš©ì„ yieldë¡œ ìˆœì°¨ì ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    else:
        return response  # ìƒì„±ëœ ì‘ë‹µì˜ ë‚´ìš©ì„ ë°˜í™˜í•©ë‹ˆë‹¤.


def tool_list_to_tool_obj(tools):
    print(f"tools: {tools}")
    tool_calls_dict = defaultdict(
        lambda: {"id": None, "function": {"arguments": "", "name": None}, "type": None}
    )

    for tool_call in tools:
        if tool_call.id is not None:
            tool_calls_dict[tool_call.index]["id"] = tool_call.id
        if tool_call.function.name is not None:
            tool_calls_dict[tool_call.index]["function"][
                "name"
            ] = tool_call.function.name
        tool_calls_dict[tool_call.index]["function"][
            "arguments"
        ] += tool_call.function.arguments
        if tool_call.type is not None:
            tool_calls_dict[tool_call.index]["type"] = tool_call.type
    tool_calls_list = list(tool_calls_dict.values())
    return {"tool_calls": tool_calls_list}


st.title("ğŸ’¬ Chatbot")

if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {
            "role": "system",
            "content": "ë„ˆëŠ” ì‚¬ìš©ìë¥¼ ë„ì™€ì£¼ëŠ” ìƒë‹´ì‚¬ì•¼.",
        },  # ì´ˆê¸° ì‹œìŠ¤í…œ ë©”ì‹œì§€
    ]

for msg in st.session_state.messages:
    if (
        msg["role"] == "assistant" or msg["role"] == "user"
    ):  # assistant í˜¹ì€ user ë©”ì‹œì§€ì¸ ê²½ìš°ë§Œ
        st.chat_message(msg["role"]).write(msg["content"])


if user_input := st.chat_input():  # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
    st.session_state.messages.append(
        {"role": "user", "content": user_input}
    )  # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
    st.chat_message("user").write(user_input)  # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë¸Œë¼ìš°ì €ì—ì„œë„ ì¶œë ¥

    ai_response = get_ai_response(st.session_state.messages, tools=tools)
    # print(ai_message)
    content = ""
    tool_calls = None
    tool_calls_chunk = []

    for chunk in ai_response:
        content_chunk = chunk.choices[0].delta.content  # â‘¡ ì²­í¬ ì† content ì¶”ì¶œ
        if content_chunk:  # â‘¢ ë§Œì•½ content_chunkê°€ ìˆë‹¤ë©´,
            print(content_chunk, end="")  # â‘£ í„°ë¯¸ë„ì— ì¤„ë°”ê¿ˆ ì—†ì´ ì´ì–´ì„œ ì¶œë ¥
            content += content_chunk  # â‘¤ contentì— ë§ë¶™ì´ê¸°
        if chunk.choices[0].delta.tool_calls:
            tool_calls_chunk += chunk.choices[0].delta.tool_calls

    print("\n===========")
    print(content)
    print("\n===========")
    tool_obj = tool_list_to_tool_obj(tool_calls_chunk)
    tool_calls = tool_obj["tool_calls"]
    print(tool_calls)
    # ai_message = ai_response.choices[0].message
    # tool_calls = ai_message.tool_calls  # AI ì‘ë‹µì— í¬í•¨ëœ tool_callsë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    if tool_calls:  # tool_callsê°€ ìˆëŠ” ê²½ìš°
        for tool_call in tool_calls:

            tool_name = tool_call["function"][
                "name"
            ]  # ì‹¤í–‰í•´ì•¼í•œë‹¤ê³  íŒë‹¨í•œ í•¨ìˆ˜ëª… ë°›ê¸°
            tool_call_id = tool_call["id"]  # tool_call ì•„ì´ë”” ë°›ê¸°
            arguments = json.loads(
                tool_call["function"]["arguments"]
            )  # ë¬¸ìì—´ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜

            if tool_name == "get_current_time":
                func_result = get_current_time(timezone=arguments["timezone"])
            elif tool_name == "get_yf_stock_info":
                func_result = get_yf_stock_info(ticker=arguments["ticker"])
            elif tool_name == "get_yf_stock_history":  # get_yf_stock_history í•¨ìˆ˜ í˜¸ì¶œ
                func_result = get_yf_stock_history(
                    ticker=arguments["ticker"], period=arguments["period"]
                )
            elif (
                tool_name == "get_yf_stock_recommendations"
            ):  # get_yf_stock_recommendations í•¨ìˆ˜ í˜¸ì¶œ
                func_result = get_yf_stock_recommendations(ticker=arguments["ticker"])

            st.session_state.messages.append(
                {
                    "role": "function",
                    "tool_call_id": tool_call_id,
                    "name": tool_name,
                    "content": func_result,
                }
            )

        st.session_state.messages.append(
            {"role": "system", "content": "ì´ì œ ì£¼ì–´ì§„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•  ì°¨ë¡€ë‹¤."}
        )
        # ai_response = get_ai_response(
        #     st.session_state.messages, tools=tools
        # )  # ë‹¤ì‹œ GPT ì‘ë‹µ ë°›ê¸°
        # ai_message = ai_response.choices[0].message
        content = ""
        with st.chat_message("assistant").empty():
            for chunk in ai_response:
                content_chunk = chunk.choices[0].delta.content
                if content_chunk:
                    print(content_chunk, end="")
                    content += content_chunk
                    st.markdown(content)

    st.session_state.messages.append(
        {"role": "assistant", "content": content}
    )  # â‘¢ AI ì‘ë‹µì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€í•©ë‹ˆë‹¤.

    print("AI\t: " + content)  # AI ì‘ë‹µ ì¶œë ¥
    # st.chat_message("assistant").write(content)  # ë¸Œë¼ìš°ì €ì— ë©”ì‹œì§€ ì¶œë ¥
