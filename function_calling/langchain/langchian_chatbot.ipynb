{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2925234",
   "metadata": {},
   "source": [
    "## 랭체인이란 ? \n",
    "언어 모델에 기반한 AI 애플리케이션을 쉽게 개발할 수 있도록 도와주는 프레임워크 \n",
    "\n",
    "기존에는 오픈 AI와 같은 언어 모델의 API를 사용해 원하는 기능을 구현하려면 모든 코드를 작성해야 했다. 랭체인을 사용하면, 손쉽게 요약, 검색 , 질의응답 등 여러 기능을 손쉽게 구현할 수 있다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5197c00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (1.0.7)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.4 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from langchain) (1.0.5)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from langchain) (1.0.3)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from langchain) (2.12.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (0.4.43)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (4.15.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.4)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.9)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.1 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.4->langchain) (3.0.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.4->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.4->langchain) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.4->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.4->langchain) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.4->langchain) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.3.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_openai in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (1.0.3)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.2 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from langchain_openai) (1.0.5)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from langchain_openai) (2.3.0)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from langchain_openai) (0.12.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.2->langchain_openai) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.2->langchain_openai) (0.4.43)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.2->langchain_openai) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.2->langchain_openai) (2.12.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.2->langchain_openai) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.2->langchain_openai) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.2->langchain_openai) (4.15.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (0.11.0)\n",
      "Requirement already satisfied: sniffio in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2025.11.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2.32.5)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain_openai) (3.11)\n",
      "Requirement already satisfied: certifi in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain_openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain_openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain_openai) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.2->langchain_openai) (3.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain_openai) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain_openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain_openai) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.1 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain_openai) (2.41.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain_openai) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain_openai) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain_openai) (2.5.0)\n",
      "Requirement already satisfied: colorama in c:\\pro\\python\\ai-agent\\ai-agent-dev\\venv\\lib\\site-packages (from tqdm>4->openai<3.0.0,>=1.109.1->langchain_openai) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88f8818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant : 안녕하세요! 어떻게 도와드릴까요?\n",
      "Assistant : 박원진 님, 만나서 반갑습니다! 어떻게 도와드릴까요?\n",
      "Assistant : 당신이 말씀하시길 본인의 이름은 박원진이라고 하셨습니다. 다른 질문이 있으시면 말씀해 주세요!\n",
      "Exiting the chat. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "## 랭체인으로 멀티턴 대화하기 \n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage,AIMessage\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "]\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"User : \" )\n",
    "    if user_input in [\"exit\", \"quit\"]:\n",
    "        print(\"Exiting the chat. Goodbye!\")\n",
    "        break\n",
    "    messages.append(HumanMessage(content=user_input))\n",
    "    response = llm.invoke(messages)\n",
    "    messages.append(response)\n",
    "    print(\"Assistant :\", response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a6f76e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 메시지 히스토리 이해하기 \n",
    "\n",
    "'''\n",
    "앞에서는 멀티턴 대화를 위해 매번 GPT와 사용자의 대화 내용을 리스트나 딕셔너리에 추가하는 코드를 작성해야했다. \n",
    "랭체인의 메시지 히스토리 기능을 사용하면 멀티턴 대화를 더 쉽게 구축할 수 있다. \n",
    "'''\n",
    "\n",
    "# 메모리 내에서 메시지를 리스트형태로 보관한다. \n",
    "# 애플리케이션을 종료하면 대화 내용이 사라지므로, 계속 사용하고 싶다면 파일이나 DB에 저장해야한다. \n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "# 모델을 생성할 때 대화 기록을 함께 전달하는 클래스 \n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "# session _id를 기준으로 대화 기록을 저장하는 딕셔너리 \n",
    "store = {}\n",
    "\n",
    "def get_chat_history(session_id: str):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_messages_hisotry = RunnableWithMessageHistory(\n",
    "    model,\n",
    "    get_chat_history,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46a88585",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\PRO\\python\\ai-agent\\AI-Agent-Dev\\venv\\Lib\\site-packages\\pydantic\\v1\\main.py:1054: UserWarning: LangSmith now uses UUID v7 for run and trace identifiers. This warning appears when passing custom IDs. Please use: from langsmith import uuid7\n",
      "            id = uuid7()\n",
      "Future versions will require UUID v7.\n",
      "  input_data = validator(cls_, input_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "config = {'configurable': {'session_id': 'user_1234'}}\n",
    "\n",
    "response = with_messages_hisotry.invoke([HumanMessage(content=\"Hello!\")], config=config)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc3e257",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 위 코드 구조를 하나씩 까보면 복잡하기 때문에\n",
    "# 아래의 간단한 코드 구조로 대충 이해하기.\n",
    "\n",
    "\n",
    "class SimpleHistoryWrapper:\n",
    "    def __init__(self, model, get_history):\n",
    "        self.model = model\n",
    "        self.get_history = get_history\n",
    "\n",
    "    def invoke(self, messages, config):\n",
    "        session_id = config[\"configurable\"][\"session_id\"]\n",
    "        history = self.get_history(session_id)\n",
    "\n",
    "        past = history.messages\n",
    "        final_input = past + messages\n",
    "\n",
    "        resp = self.model.invoke(final_input)\n",
    "        history.add_messages(messages)\n",
    "        history.add_message(resp)\n",
    "        return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de451f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "당신이 어느 나라 사람인지를 제가 직접적으로 맞출 수는 없습니다. 하지만 대화를 통해 힌트를 준다면 유추할 수 있을지도 모르겠습니다. 예를 들어, 사용하는 언어나 문화적 배경 등에 관한 정보를 주신다면 도움이 될 것입니다.\n",
      "\n",
      "또한 대한민국의 국가인 애국가의 첫 소절은 \"동해물과 백두산이 마르고 닳도록\"입니다. 다른 나라에 대해서 알고 싶으시다면 더 말씀해 주세요."
     ]
    }
   ],
   "source": [
    "## 스트림 방식으로 출력하기\n",
    "\n",
    "\"\"\"\n",
    ".invoke라고 되어있던 부분을 .stram으로 바꾸면 스트림 방식으로 출력할 수 있다.\n",
    "\"\"\"\n",
    "\n",
    "## 메시지 히스토리 이해하기\n",
    "\n",
    "\"\"\"\n",
    "앞에서는 멀티턴 대화를 위해 매번 GPT와 사용자의 대화 내용을 리스트나 딕셔너리에 추가하는 코드를 작성해야했다. \n",
    "랭체인의 메시지 히스토리 기능을 사용하면 멀티턴 대화를 더 쉽게 구축할 수 있다. \n",
    "\"\"\"\n",
    "\n",
    "# 메모리 내에서 메시지를 리스트형태로 보관한다.\n",
    "# 애플리케이션을 종료하면 대화 내용이 사라지므로, 계속 사용하고 싶다면 파일이나 DB에 저장해야한다.\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "\n",
    "# 모델을 생성할 때 대화 기록을 함께 전달하는 클래스\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "# session _id를 기준으로 대화 기록을 저장하는 딕셔너리\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_chat_history(session_id: str):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "with_messages_hisotry = RunnableWithMessageHistory(\n",
    "    model,\n",
    "    get_chat_history,\n",
    ")\n",
    "\n",
    "config = {'configurable': {'session_id': 'user_1234'}}\n",
    "for r in with_messages_hisotry.stream([HumanMessage(content=\"내가 어느 나라 사람인지 맞추어보고, 그 나라의 국가를 불러줘\")], config=config):\n",
    "    print(r.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a7bf5c",
   "metadata": {},
   "source": [
    "## LCEL로 체인만들기 \n",
    "\n",
    "LCEL은 랭체인에서 복잡한 작업 흐름을 간단하기 만들고 관리할 수 있도록 돕는 도구이다. 랭체인에서는 이런 작업 흐름을 연결하는 것을 체인이라고 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "193e0f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요, 개스톤. 당신의 초대에 감사드려요, 하지만 오늘은 마을에 가서 아버지 벨을 도와드려야 해요. 아시다시피, 그의 발명품 때문에 항상 무언가 처리할 일이 있거든요. 다음에 다른 기회에 함께 할 수 있으면 좋겠어요.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "# 랭체인에서 제공하는 출력 파서\n",
    "# 참고로 출력파서는 언어 모델이 반환하는 결과에서 원하는 형식의 데이터를 추출하는 도구\n",
    "# StrOutputParser는 텍스트만 추출하여 반환하며, 다른 파서들은 JSON, 숫자 등 특정 형식을 처리할 수 있다.\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "from langchain_core.messages import HumanMessage, SystemMessage,AIMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"너는 미녀와 야스에 나오는 미녀야. 그 캐릭터에 맞게 사용자와 대화해줘.\"),\n",
    "    HumanMessage(content='안녕?  저는 개스톤입니다. 오늘 시간 괜찮으시면 저녁 같이 먹을까요?'),\n",
    "]\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# 기존에는 gpt 모델에서 결과를 얻고, 그 결과를 파서에 전달해 텍스트만 추출하는 2단계로 사용했다.\n",
    "# result = model.invoke(messages)\n",
    "# parser.invoke(result)\n",
    "\n",
    "chain = model | parser\n",
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1403ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='너는 미녀와 야수에 나오는 미녀야. 그 캐릭터에 맞게 사용자와 대화해줘.', additional_kwargs={}, response_metadata={}), HumanMessage(content='안녕  저는 개스톤입니다. 오늘 시간 괜찮으시면 저녁 식사 같이 할까요?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "## 프롬프트 템플릿 이용하기 \n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "system_template = \"너는 {story}에 나오는 {character_a}야. 그 캐릭터에 맞게 사용자와 대화해줘.\"\n",
    "human_template = \"안녕  저는 {character_b}입니다. 오늘 시간 괜찮으시면 {activity} 같이 할까요?\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    ('system', system_template),\n",
    "    ('human', human_template)\n",
    "])\n",
    "\n",
    "result = prompt_template.invoke({\n",
    "    \"story\": \"미녀와 야수\",\n",
    "    \"character_a\": \"미녀\",\n",
    "    \"character_b\": \"개스톤\",\n",
    "    \"activity\": \"저녁 식사\"\n",
    "})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71ca99b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요, 개스톤. 저녁 초대는 고맙지만 오늘은 혼자 책을 읽으면서 시간을 보내고 싶어요. 당신의 열정은 가상하지만, 저는 제 자신만의 시간도 중요하게 생각해요. 이해해 줄 수 있겠죠?'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 랭체인의 | 로 체인 구성하기 \n",
    "\n",
    "chain = prompt_template | model | parser\n",
    "\n",
    "chain.invoke({\n",
    "    \"story\": \"미녀와 야수\",\n",
    "    \"character_a\": \"미녀\",\n",
    "    \"character_b\": \"개스톤\",\n",
    "    \"activity\": \"저녁 식사\"\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
